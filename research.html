<!DOCTYPE HTML>
<html>

<head>
  <title>SUN Lab</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body>
  <div id="main">

    <div id="header">
      <div id="logo">
        <div id="logo_text">
          <!-- class="logo_colour", allows you to change the colour of the text -->
          <h1><a href="index.html"><span class="logo_colour">SUN Lab</span></a></h1>
          <h2>Yokohama National University</h2>
        </div>
      </div>
      <div id="menubar">
        <ul id="menu">
          <!-- put class="selected" in the li tag for the selected page - to highlight which page you're on -->
          <li><a href="index.html">Home</a></li>
          <li><a href="publications.html">Publication</a></li>
          <li><a href="member.html">Member</a></li>
          <li class="selected"><a href="research.html">Research</a></li>
          <li><a href="event.html">Event</a></li>
        </ul>
      </div>
    </div>
    <div id="site_content">

        <!-- insert the page content here -->
        <h1>Learned Image Codec</h1>
        <p>Traditional image compresion standards have been developed for more than 30 years. On the other hand, with the developments of neural network, learned image compression (LIC) has shown a superior coding ability than the traditional image compression standards. Two proposed LIC networks (CVPR'20, CVPR'23) are given below.</p>
        <div style="text-align:center">
          <img src="cvpr20.png" width="760" height="239"> 
          <p> Proposed LIC with GMM and attention, which was the state-of-the-art until 2020. </p>
          <img src="cvpr23.png" width="760" height="239">
          <p> Proposed LIC with mixed transformer and CNN, which was the state-of-the-art until 2023.</p>
        </div>

        <h1>Learned Video Codec</h1>
        <p>Traditional video compresion standards have also been developed for over 30 years. Similar to the case of image compression, learned video compression (LVC) has demonstrated superior coding efficiency compared to traditional video compression standards. The proposed LVC network (CVPR'25) is shown below.</p>
        <div style="text-align:center">
          <img src="cvpr25.png" width="760" height="239"> 
          <p> Proposed LVC with feature level attention. </p>
        </div>

        <h1>Image Coding for Machine</h1>
        <p>Cisco reported that the communication for the machine-to-machine will occupy up to 50% of all the communication in the coming IoT society. Therefore, reducing the transmission burden between machines becomes extremely important. Differently from human vision, image coding for machine aims to improve the accuracy of machine vision tasks such as object detection/tracking.</p>
        <div style="text-align:center">
          <img src="pcs22.png" width="760" height="239"> 
          <p> Proposed semantic segmentation in learned compressed domain</p>
        </div>

        <h1>FPGA Neural Network Engine</h1>
        <p>Among various hardware platforms, FPGA has the advantage of high hardware utilization and power efficiency compared with CPU and GPU. In addition, compared with ASIC, FPGA is more flexible and reconfigurable which can keep up with the fast developments of neural network models. We developed an FPGA neural engine with fine-grained pipeline, and built a FPGA codec system for LIC.</p>
        <div style="text-align:center">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/-unSbqsUS8Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          <p> We have a camera (right bottom) which captures the 720p 30fps raw video in the right display. Then one Xilinx FPGA board VCU118 is in charge of encoding. The encoded bitstream is sent to another FPGA board for the decoding. Finally, the decoded video is shown in the left display.</p>
        </div>
        <div style="text-align:center">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/Y4QO2h0LEDQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          <p> To evaluate the latency, we capture the real-time timestamps, and the difference between the raw timestamp and decoded timestamp is the end-to-end latency, which is around 560 ms. We also use the power meter to evaluate the real power for the overall FPGA board.</p>
        </div>

        <h1>ASIC Chip Design</h1>
        <div style="text-align:center">
          <img src="isscc16.png" width="300" height="300"> 
          <p>Developed 8K@120fps HEVC decoder chip in which I was in charge of Inverse Transform (IT) and De-quantization (IQ) components.</p>
        </div>

    </div>
    <div id="content_footer"></div>
    <div id="footer">
      <p><a href="index.html">Home</a> | <a href="publications.html">Publications</a> | <a href="member.html">Member</a> | <a href="research.html">Research</a> | <a href="event.html">Event</a></p>
      <p><a href="http://www.html5webtemplates.co.uk">design from HTML5webtemplates.co.uk</a></p>
    </div>
  </div>
</body>
</html>
